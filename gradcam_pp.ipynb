{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_a-_Ju_LQ-GT"
   },
   "source": [
    "# Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjM4mG-HUDqb",
    "outputId": "355b6b33-30f6-44f7-f2ea-4a38f573ce96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pydicom\n",
      "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 7.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-2.3.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 4.1 MB/s \n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 1.1.0\n",
      "    Uninstalling xlrd-1.1.0:\n",
      "      Successfully uninstalled xlrd-1.1.0\n",
      "Successfully installed xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# installo le librerie\n",
    "!pip install pydicom\n",
    "!pip install pandas>=1.2.0\n",
    "!pip install xlrd>=1.2.0.\n",
    "!pip install --upgrade xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7NZLIIA-sUx"
   },
   "outputs": [],
   "source": [
    "# importo le librerie\n",
    "import sys  # system for info\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # numpy\n",
    "from PIL import Image\n",
    "import pandas as pd # pandas\n",
    "from pathlib import Path    #path library for paths management\n",
    "from tqdm import tqdm   #tqdm for loading bars\n",
    "import os   # os for paths and dirs\n",
    "import pydicom  # pydicom library for dicom file import\n",
    "from tensorflow import keras # per caricare il modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7OY6AEpQ-Ga"
   },
   "source": [
    "# UTILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbrdZcP6Q-Gb"
   },
   "source": [
    "## UTILS PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwGMk9KJQ-Gb"
   },
   "outputs": [],
   "source": [
    "# crea i path necessari\n",
    "databasePathIMAGES = Path('drive/MyDrive/Dataset/TrainSet (1)/TrainSet/')     #path of the images png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xy5e1j3FQ-Gc"
   },
   "source": [
    "## RANDOM NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoQQDlopQ-Gc"
   },
   "outputs": [],
   "source": [
    "random_seed = 42    #random seed per poter riprodurre l'esperimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-aNq1RyQ-Gc"
   },
   "source": [
    "## GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXkuIzrBQ-Gc"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224  #dimensione delle immagini in input (224x224)\n",
    "CLASS_NAMES = ['MILD', 'SEVERE']    #valori delle label T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Rh_nRmQ-Gd"
   },
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTzqdZe6Q-Gd"
   },
   "source": [
    "### Loader Dicom from Winner Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGpFJdOwQ-Gd"
   },
   "outputs": [],
   "source": [
    "def clahe_transform(img):\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(4, 4))\n",
    "    img = clahe.apply((img * 255).astype(np.uint8)) / 255\n",
    "    return img\n",
    "\n",
    "def normalize(img, min_val=None, max_val=None):\n",
    "    if not min_val:\n",
    "        min_val = img.min()\n",
    "    if not max_val:\n",
    "        max_val = img.max()\n",
    "    img = (img - min_val) / (max_val - min_val)\n",
    "    # img -= img.mean()\n",
    "    # img /= img.std()\n",
    "    return img\n",
    "\n",
    "def load_img(img_path):\n",
    "    filename, extension = os.path.splitext(img_path)\n",
    "    if extension == \".dcm\":\n",
    "        dicom = pydicom.dcmread(img_path)\n",
    "        img = dicom.pixel_array.astype(float)\n",
    "        photometric_interpretation = dicom.PhotometricInterpretation\n",
    "    else:\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img).astype(float)\n",
    "        photometric_interpretation = 'MONOCHROME1'\n",
    "    return img, photometric_interpretation\n",
    "\n",
    "\n",
    "# def loader(img_path, img_dim, mask_path=None, box=None, clahe=False):\n",
    "def loader(img_path, img_dim, clahe=False):\n",
    "    # Img\n",
    "    # img_vec = []\n",
    "    img, photometric_interpretation = load_img(img_path)\n",
    "    min_val, max_val = img.min(), img.max()\n",
    "\n",
    "    # Pathometric Interpretation\n",
    "    if photometric_interpretation == 'MONOCHROME1':\n",
    "        img = np.interp(img, (min_val, max_val), (max_val, min_val))\n",
    "\n",
    "    # To Grayscale\n",
    "    # if img.ndim > 2:\n",
    "        # img = img.mean(axis=2)\n",
    "\n",
    "    # plt.imshow(img)\n",
    "\n",
    "    # Resize\n",
    "    img = cv2.resize(img, (img_dim, img_dim))\n",
    "    # Normalize\n",
    "    img = normalize(img, min_val=min_val, max_val=max_val)\n",
    "    # CLAHE\n",
    "    if clahe:\n",
    "        img = clahe_transform(img)\n",
    "    \n",
    "    # To 3 Channels\n",
    "    img = np.stack((img, img, img), axis=-1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def loadAllImgToArray(DB,dimention,cName,basePt):\n",
    "    paths = DB[cName].to_list()\n",
    "\n",
    "    # print(paths)\n",
    "    imgs = []\n",
    "    for p in tqdm(paths):\n",
    "        img = loader(basePt / p , dimention, clahe= True)\n",
    "        # for i in img:\n",
    "        imgs.append(img)\n",
    "\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "    return imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjwtpJUnQ-Ge"
   },
   "source": [
    "# Load From DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zZEBm6mQ-Ge"
   },
   "source": [
    "### Import Database DICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UToRw5LVjHf-",
    "outputId": "7400c615-a811-42e6-f5bd-f0152599003d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# monto il drive dal quale prendere le immagini\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoacXR_nQ-Gh"
   },
   "source": [
    "# Model load and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzT4y6yJQ-Gj"
   },
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDHG7XNqQ-Gj"
   },
   "outputs": [],
   "source": [
    "# carico il modello pretrainato\n",
    "model = keras.models.load_model('drive/MyDrive/my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI2KExXDbbrx"
   },
   "source": [
    "# GRAD-CAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQkjO3Qhbejv",
    "outputId": "acc538a1-8abe-414c-ea48-f0f8f4ffaa93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-gradcam\n",
      "  Downloading pytorch-gradcam-0.2.1.tar.gz (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 8.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from pytorch-gradcam) (4.6.0.66)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-gradcam) (1.21.6)\n",
      "Building wheels for collected packages: pytorch-gradcam\n",
      "  Building wheel for pytorch-gradcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pytorch-gradcam: filename=pytorch_gradcam-0.2.1-py3-none-any.whl size=5269 sha256=9dfb84dd7e894c3c3e5d9ecec35e95aee01c629fa1fe702d20e9b47265a184dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/e7/da/b13a71980c3a787414e5ff8e156701c561c6322636396d71cc\n",
      "Successfully built pytorch-gradcam\n",
      "Installing collected packages: pytorch-gradcam\n",
      "Successfully installed pytorch-gradcam-0.2.1\n",
      "Cloning into 'tf_keras_gradcamplusplus'...\n",
      "remote: Enumerating objects: 100, done.\u001b[K\n",
      "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 100 (delta 35), reused 80 (delta 21), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (100/100), 13.66 MiB | 25.25 MiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n"
     ]
    }
   ],
   "source": [
    "# installo le librerie per il framework gradcam\n",
    "!pip install utils\n",
    "!pip install pytorch-gradcam\n",
    "!git clone https://github.com/samson6460/tf_keras_gradcamplusplus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dIVrSUxbdPi"
   },
   "outputs": [],
   "source": [
    "# importo le librerie per il framework gradcam\n",
    "sys.path.append('tf_keras_gradcamplusplus')\n",
    "import utils #Dempster-Shafer layer\n",
    "import gradcam #Utility layer for training\n",
    "from tf_keras_gradcamplusplus.utils import vgg16_mura_model, preprocess_image, show_imgwithheat\n",
    "from tf_keras_gradcamplusplus.gradcam import grad_cam, grad_cam_plus\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmqXldOCod1x"
   },
   "outputs": [],
   "source": [
    "# imposto le classi\n",
    "class_names = ['MILD', 'SEVERE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNGLtjIucBXi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JFFTOk-u_IFl"
   },
   "outputs": [],
   "source": [
    "# funzione che preso in input il nome di un'immagine, fornisce in output la label assegnata e l'heatmap relativa\n",
    "def single_img(img_name):\n",
    "  s = {'ImageFile':[img_name]}\n",
    "  image_df = pd.DataFrame(s)\n",
    "  loaded_image = loadAllImgToArray(image_df,IMAGE_SIZE,'ImageFile',databasePathIMAGES)\n",
    "\n",
    "  heatmap_plus = grad_cam_plus(\n",
    "    model,\n",
    "    loaded_image[0],\n",
    "    #layer_name = \"conv5_block3_out\",\n",
    "     layer_name = \"conv4_block6_out\",\n",
    "    # layer_name = \"conv3_block4_out\",\n",
    "    # layer_name = \"conv2_block3_out\",\n",
    "    label_name = ['MILD', 'SEVERE']\n",
    "    )\n",
    "  \n",
    "  show_imgwithheat('drive/MyDrive/Dataset/TrainSet (1)/TrainSet/'+image_df.at[0, 'ImageFile'], heatmap_plus, alpha = 0.3)\n",
    "\n",
    "single_img('P_2_50.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4IOBNOKJKCp"
   },
   "outputs": [],
   "source": [
    "# funzione in ausilio a multi_img che, passate una heatmap e un immagine sovrappone le due\n",
    "def visualizeGradCAMplus(img,hm, alpha = 0.4,outputArray = True):\n",
    "    heatmap = cv2.resize(hm, (img.shape[1], img.shape[0]))\n",
    "    heatmap = (heatmap*255).astype(\"uint8\")\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * alpha + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(\"uint8\")\n",
    "    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    imgwithheat = Image.fromarray(superimposed_img)\n",
    "    return imgwithheat if outputArray else plt.imshow(imgwithheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_8rpBipJdFw"
   },
   "outputs": [],
   "source": [
    "# funzione che preso in input più nomi di immagini, fornisce in output le relative label assegnate con le heatmap associate\n",
    "def multi_img(img_name):\n",
    "\n",
    "  s = {'ImageFile':img_name}\n",
    "  image_df = pd.DataFrame(s)\n",
    "\n",
    "  # print(image_df.type())\n",
    "\n",
    "  loaded_image = loadAllImgToArray(image_df,IMAGE_SIZE,'ImageFile',databasePathIMAGES)\n",
    "\n",
    "  edge = math.ceil(math.sqrt(64))\n",
    "  i = 0\n",
    "\n",
    "  figure = plt.figure()\n",
    "  figure.set_size_inches(50, 30)\n",
    "\n",
    "  for i in range(len(image_df)):\n",
    "      im = loaded_image[i]\n",
    "\n",
    "      if i>63:\n",
    "          break\n",
    "      ax = plt.subplot(edge, edge, i + 1)\n",
    "\n",
    "      # hm = gradcam.grad_cam(CNN,im,layer_name='average_pooling2d_4_CNN')\n",
    "      hm = grad_cam_plus(model,im,layer_name='conv5_block3_out', label_name = ['MILD', 'SEVERE'])\n",
    "\n",
    "      img_hm = visualizeGradCAMplus(im,hm)\n",
    "\n",
    "      plt.imshow(img_hm,)\n",
    "\n",
    "      im2pred = np.reshape(im,(1,224,224,3))\n",
    "      lab = class_names[0]\n",
    "      pr = round(model.predict(im2pred)[0][0])\n",
    "      pr = class_names[int(pr)]\n",
    "      \n",
    "      plt.axis(\"off\")\n",
    "\n",
    "      plt.axis(\"off\")\n",
    "      \n",
    "      i = i+1\n",
    "\n",
    "multi_img(['P_2_50.png', 'P_2_51.png', 'P_2_52.png', 'P_2_53.png', 'P_2_55.png'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8acea683dfa1ff2613312f10985a069d0785967c839d3d347b7388426a15b8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
